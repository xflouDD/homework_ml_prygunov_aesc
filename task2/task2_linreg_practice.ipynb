{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxVsGvTv9MPM"
      },
      "source": [
        "# ДЗ Линейная регрессия\n",
        "\n",
        "В данном задании мы рассмотрим набор данных об учащихся, собранный в 2006 году в одной из школ Португалии. Данные представлены в неудобном для машинного обучения виде, и содержат мусор. Ваша задача &mdash; привести их к надлежащему виду и обучить на них простую модель.\n",
        "\n",
        "Данные состоят из четырех файлов:\n",
        "- data.csv &mdash; основная таблица с информацией о учащихся\n",
        "- scores.csv &mdash; список финальных оценок по одному из предметов (20-балльная шкала переведенная в проценты)\n",
        "- attendance.csv &mdash; таблица посещений занятий по этому предмету\n",
        "- school_support.txt &mdash; список учащихся, которым оказывается финансовая поддержка\n",
        "\n",
        "Ваша задача &mdash; построить модель для предсказания финальных оценок исходя из всех остальных данных и проверить качество ее работы с помощью кросс-валидации. В качестве алгоритма мы будем использовать линейную регрессию\n",
        "\n",
        "Расшифровка столбцов в data.csv для справки:\n",
        "- age &mdash; возраст\n",
        "- Medu &mdash; уровень образования матери (по некоторой условной шкале)\n",
        "- Fedu &mdash; уровень образования отца (по некоторой условной шкале)\n",
        "- traveltime &mdash; время в пути до школы (1 – < 15 мин., 2 – от 15 до 30 мин., 3 – от 30 мин. to 1 ч.\n",
        "или 4 – > 1 ч.)\n",
        "- studytime &mdash; время, затрачиваемое на занятия вне школы (1 – < 2 ч., 2 – от 2 до 5 ч., 3 – от 5 до 10 ч. или 4 – > 10 ч.)\n",
        "- famrel &mdash; насколько хорошие отношения в семье у учащегося (по некоторой условной шкале)\n",
        "- freetime &mdash; количество свободного времени вне школы (по некоторой условной шкале)\n",
        "- goout &mdash; время, затрачиваемое на общение с друзьями (по некоторой условной шкале)\n",
        "- Dalc &mdash; количество употребления алкоголя в учебные дни (по некоторой условной шкале)\n",
        "- Walc &mdash; количество употребления алкоголя в неучебные дни (по некоторой условной шкале)\n",
        "- health &mdash; уровень здоровья (по некоторой условной шкале)\n",
        "- sex_M &mdash; пол: мужской (1) или женский (0)\n",
        "- address_U &mdash; живет ли учащийся в городе (1) или в пригороде (0)\n",
        "- famsize_LE3 &mdash; размер семьи: не больше 3 человек (1) или больше (0)\n",
        "- Pstatus_T &mdash; живут ли родители вместе (1) или отдельно (0)\n",
        "- nursery &mdash; посещал ли учащийся детский сад\n",
        "- plans_university &mdash; планирует ли учащийся поступать в университет (-1 или 1)\n",
        "- past_failures &mdash; количество неудовлетворительных оценок по другим предметам ранее (от 0 до 4)\n",
        "\n",
        "*Примечание. Несколько признаков в данных содержат ошибки/проблемы/некорректности. Эти проблемы нужно исправить. Для\n",
        "проверки &mdash; всего в данных таких проблем четыре.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDt8HcS39MPT"
      },
      "source": [
        "### Задача 1: сломанный признак (а может и не один)\n",
        "__(1 балл)__\n",
        "\n",
        "Загрузите таблицу data.csv.\n",
        "\n",
        "Найдите в данных сломанный признак (он не соответствует описанию) и исправьте его."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "F9Kyd8sR9MPU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "data = pd.read_csv('data.csv')\n",
        "\n",
        "check = []\n",
        "\n",
        "rows_of_all_table = 649\n",
        "\n",
        "s = 'plans_universitypast_failures'\n",
        "\n",
        "for i in range (rows_of_all_table):\n",
        "  if(data.loc[i, s] < 0):\n",
        "    check.append(True)\n",
        "    data.loc[i, s] *= -1\n",
        "    data.loc[i, s] = str(data.loc[i, s])\n",
        "    data.loc[i, s] = data.loc[i, s][0] + ' ' + data.loc[i, s][1]\n",
        "  else :\n",
        "    check.append(False)\n",
        "    data.loc[i, s] = str(data.loc[i, s])\n",
        "    data.loc[i, s] = data.loc[i, s][0] + ' ' + data.loc[i, s][1]\n",
        "\n",
        "#print(data)\n",
        "\n",
        "\n",
        "new_df = data[s].str.split(' ',expand=True)\n",
        "\n",
        "new_df.columns=['plans_university','past_failures']\n",
        "\n",
        "data = pd.concat([data,new_df],axis=1)\n",
        "\n",
        "data = data.drop(s,axis=1)\n",
        "\n",
        "a = 'plans_university'\n",
        "b = 'past_failures'\n",
        "\n",
        "for i in range (rows_of_all_table):\n",
        "  data.loc[i, b] = int(data.loc[i, b])\n",
        "  data.loc[i, a] = int(data.loc[i, a])\n",
        "  if check[i] == True:\n",
        "    data.loc[i, a] *= -1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (rows_of_all_table):\n",
        "  if(data.loc[i, 'age'] > 1750):\n",
        "    data.loc[i, 'age'] = 2006 - data.loc[i, 'age']"
      ],
      "metadata": {
        "id": "f4ReZpFE2AEN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaGN23HX9MPV"
      },
      "source": [
        "### Задача 2: пропуски в данных\n",
        "__(1 балл)__\n",
        "\n",
        "Проверьте, есть ли в данных пропуски (значения NaN). Замените все пропущенные значения на среднее значение этого признака по столбцу.\n",
        "\n",
        "__(+1 балл)__\n",
        "\n",
        "Дополнительно сравните качество замены на среднее по столбцу и на медиану по столбцу\n",
        "\n",
        "\n",
        "*Hint: изучите в pandas функции loc, isnull, а также передачу булевых массивов в качестве индексов.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "73KwcR4E9MPW"
      },
      "outputs": [],
      "source": [
        "data_columns_before = data.columns\n",
        "\n",
        "array_of_nuns = pd.DataFrame()\n",
        "\n",
        "for i in data.columns:\n",
        "  sum = 0\n",
        "  c = 0\n",
        "  bool_series = pd.isnull(data[i])\n",
        "  array_of_nuns[i] = bool_series\n",
        "  for j in range(rows_of_all_table):\n",
        "    if bool_series[j] == False:\n",
        "      sum += data.loc[j, i]\n",
        "      c += 1\n",
        "  avg = round(sum / c)\n",
        "  for j in range(rows_of_all_table):\n",
        "    if bool_series[j] == True:\n",
        "      data.loc[j, i] = avg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# take median to NaN\n",
        "\n",
        "for i in data_columns_before:\n",
        "  bool_series = data[i].values is not None\n",
        "  a = []\n",
        "  for j in range(rows_of_all_table):\n",
        "    if array_of_nuns.loc[j, i] == False:\n",
        "      a.append(data.loc[j, i])\n",
        "  a.sort()\n",
        "  n = len(a)\n",
        "  for j in range(rows_of_all_table):\n",
        "    if array_of_nuns.loc[j, i] == False:\n",
        "      data.loc[j, i] = a[n // 2]\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "id": "xyfMv3c6KJdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8556feaf-c0f5-45fd-b63b-dd33269fe821"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          age  Medu  Fedu  traveltime  studytime  famrel  freetime  goout  \\\n",
            "0    0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "1    0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "2    0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "3    0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "4    0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "..        ...   ...   ...         ...        ...     ...       ...    ...   \n",
            "644  0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "645  0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "646  0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "647  0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "648  0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "\n",
            "     Dalc  Walc  health  sex_M  address_U  famsize_LE3  Pstatus_T  nursery  \\\n",
            "0     0.0  0.25    0.75      0          1            0          1        1   \n",
            "1     0.0  0.25    0.75      0          1            0          1        1   \n",
            "2     0.0  0.25    0.75      0          1            0          1        1   \n",
            "3     0.0  0.25    0.75      0          1            0          1        1   \n",
            "4     0.0  0.25    0.75      0          1            0          1        1   \n",
            "..    ...   ...     ...    ...        ...          ...        ...      ...   \n",
            "644   0.0  0.25    0.75      0          1            0          1        1   \n",
            "645   0.0  0.25    0.75      0          1            0          1        1   \n",
            "646   0.0  0.25    0.75      0          1            0          1        1   \n",
            "647   0.0  0.25    0.75      0          1            0          1        1   \n",
            "648   0.0  0.25    0.75      0          1            0          1        1   \n",
            "\n",
            "    plans_university past_failures   attend  support  \n",
            "0                1.0           0.0  0.81250        0  \n",
            "1                1.0           0.0  0.93750        0  \n",
            "2                1.0           0.0  1.00000        0  \n",
            "3                1.0           0.0  0.68750        0  \n",
            "4                1.0           0.0  1.00000        0  \n",
            "..               ...           ...      ...      ...  \n",
            "644              1.0           0.0  0.93750        0  \n",
            "645              1.0           0.0  0.93750        0  \n",
            "646              1.0           0.0  0.34375        0  \n",
            "647              1.0           0.0  0.81250        0  \n",
            "648              1.0           0.0  0.93750        0  \n",
            "\n",
            "[649 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrikVvaO9MPW"
      },
      "source": [
        "### Задача 3: нормализация данных\n",
        "__(1 балл)__\n",
        "\n",
        "Нормализуйте данные любым способом"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "ke3eN6Gr9MPX"
      },
      "outputs": [],
      "source": [
        "for i in data.columns:\n",
        "  mn = 1e9\n",
        "  mx = -1e9\n",
        "  for j in range(rows_of_all_table):\n",
        "    mx = max(mx, data.loc[j, i]);\n",
        "    mn = min(mn, data.loc[j, i]);\n",
        "  for j in range(rows_of_all_table):\n",
        "    data.loc[j, i] = (data.loc[j, i] - mn) / (mx - mn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRWZpGM29MPX"
      },
      "source": [
        "### Задача 4: кросс-валидация для исходных данных\n",
        "__(1 балл)__\n",
        "\n",
        "Загрузите файл scores.csv и протестируйте, как линейная регрессия предсказывает ответ сейчас (с помощью кросс-валидации).\n",
        "\n",
        "*Hint: воспользуйтесь sklearn.linear_model и sklearn.model_selection.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KMQrCfrR9MPY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66dda392-e11c-4d1f-b836-0586ae22e3ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.21881645, 0.25841768, 0.14161857, 0.23287806])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "scores = pd.read_csv('scores.csv')\n",
        "X = data.values\n",
        "y = scores.values\n",
        "model = LinearRegression()\n",
        "res = cross_validate(model, data.values, scores.values, cv = 4)\n",
        "res['test_score']\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV0rYGba9MPY"
      },
      "source": [
        "### Задача 5: полные данные\n",
        "__(2 балла)__\n",
        "\n",
        "Воспользуйтесь файлами attendance.csv и school_support.txt для того, чтобы добавить новые признаки в данные. Желательно по максимуму использовать возможности pandas для упрощения преобразований.\n",
        "\n",
        "school_suport число в строке значит что i-ый школьник из исходной таблицы получал мат помощь (обратите внимание что строк в файле меньше, подумайте как правильно импортировать данные)\n",
        "\n",
        "Попробуйте несколько способов добавления полных данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "ThzfyMop9MPZ"
      },
      "outputs": [],
      "source": [
        "attend = pd.read_csv('attendance.csv', delimiter = \";\")\n",
        "support = pd.read_table('school_support.txt')\n",
        "\n",
        "a = []\n",
        "\n",
        "for j in range(rows_of_all_table):\n",
        "  cnt = 0\n",
        "  for i in attend.columns:\n",
        "    if attend.loc[j, i] == '+':\n",
        "      cnt += 1\n",
        "  a.append(cnt)\n",
        "\n",
        "data['attend'] = a\n",
        "\n",
        "a = [0] * rows_of_all_table\n",
        "\n",
        "for i in range(len(support)):\n",
        "  a[support.loc[i, 'support']] = 1\n",
        "\n",
        "data['support'] = a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL949S3U9MPZ"
      },
      "source": [
        "### Задача 6: борьба с выбросами\n",
        "__(1.5 балла)__\n",
        "\n",
        "Качество предсказания может ухудшаться, если в данных присутствуют корректные значения признаков (с точки зрения чтения данных и применения методов), но не соответствующие реальным объектам. Например, данные могли быть введены в неверном формате, а потом слишком грубо приведены к общему виду, из-за чего ошибка не была замечена.\n",
        "Попробуем от такого избавиться &mdash; а для этого такие объекты нужно сначала найти. Конечно, нам еще недоступны многие продвинутые способы, но давайте попробуем обойтись простыми.\n",
        "\n",
        "Первый способ это сделать &mdash; посмотреть для каждого признака на распределение его значений и проверить крайние значения на правдоподобность. (постройте гистограммы для признаков, как минимум для подозрительных)\n",
        "\n",
        "*Hint 1: используйте функцию DataFrame.hist*\n",
        "\n",
        "*Hint 2: в описании датасета выше есть информация, необходимая для восстановления правильных значений*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "-I67XFwp9MPZ"
      },
      "outputs": [],
      "source": [
        "# for i in data.columns:\n",
        "#   data.hist(column=f'{i}')\n",
        "\n",
        "s = 'traveltime'\n",
        "\n",
        "for i in range(rows_of_all_table):\n",
        "  if(data.loc[i, s] > 4):\n",
        "    if(data.loc[i, s] < 15):\n",
        "      data.loc[i, s] = 1\n",
        "    elif data.loc[i, s] < 30:\n",
        "      data.loc[i, s] = 2\n",
        "    elif data.loc[i, s] < 60:\n",
        "      data.loc[i, s] = 3\n",
        "    else :\n",
        "      data.loc[i, s] = 4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66Ss4ocv9MPZ"
      },
      "source": [
        "__(1.5 балла)__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI9p3ved9MPa"
      },
      "source": [
        "Другой простой способ найти выбросы &mdash; сделать предсказаниепосчитать ошибку на каждом объекте по отдельности и посмотреть на объекты с наибольшей ошибкой. Обратите внимание, что просто удалять все объекты с высокой ошибкой нельзя &mdash; это, конечно, хороший способ добиться меньшей ошибки (на данной выборке), но одновременно вы ухудшите обобщающую способность алгоритма. Вместо этого вам нужно найти однозначно ошибочные записи и их исправить.\n",
        "\n",
        "*Hint: возможно, все проблемы уже были найдены первым способом; для проверки &mdash; в сумме здесь нужно исправить 3 проблемы.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUG331vZ9MPa"
      },
      "source": [
        "Для поиска ошибки на одном отдельном обьекте придётся обучить линейную регрессию руками. Частичный пример, допишите код. Постройте гистограмму распределения ошибок"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "70i28fgw9MPa",
        "outputId": "a28f4c02-1797-41f7-94d9-8fd063f81044",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4102.0523520078905, 4102.0523520078905, 4102.0523520078905, 4102.0523520078905, 4102.0523520078905, 4102.0523520078905, 4102.0523520078905, 4102.0523520078905, 4102.0523520078905, 4102.0523520078905, 4102.0523520078905, 4102.0523520078905, 4102.0523520078905, 4102.0523520078905, 4102.0523520078905, 4057.341765425726, 4038.2550854619412, 4031.902858807347, 4031.902858807347, 4012.8761788435613, 3486.5796865483967, 1524.6890247104202, 1159.216359250926, 1159.216359250926, 1159.216359250926, 958.0717082775025, 958.0717082775025, 843.743693791432, 843.743693791432, 843.743693791432, 843.743693791432, 843.743693791432, 843.743693791432, 843.743693791432, 843.743693791432, 843.743693791432, 673.5443737369966, 673.5443737369966, 673.5443737369966, 673.5443737369966, 673.5443737369966, 673.5443737369966, 673.5443737369966, 673.5443737369966, 673.5443737369966, 673.5443737369966, 673.5443737369966, 673.5443737369966, 673.5443737369966, 673.5443737369966, 673.5443737369966, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 578.2710283319378, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 439.01703919649066, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 362.79836287244365, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 254.48970465598478, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 197.32569741294952, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 119.96237011547892, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 81.85303195345541, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 35.43503557497304, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 16.380366493961287, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632, 0.9077010344671632]\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "from sklearn import linear_model\n",
        "X1 = data.values\n",
        "y1 = scores.values\n",
        "regression = linear_model.LinearRegression().fit(X1, y1)\n",
        "error = []\n",
        "for i in X1:\n",
        "  j = [i]\n",
        "  prediction = regression.predict(j)\n",
        "  error.append((prediction[0] - y)**2)\n",
        "array_of_errors = []\n",
        "for i in error[0]:\n",
        "  array_of_errors.append(i[0])\n",
        "\n",
        "array_of_errors.sort()\n",
        "array_of_errors.reverse()\n",
        "print(array_of_errors)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "McZkkqn_1C5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Все ошибки были исправлены заранее, ошибки в предсказании оценок являются нормальными"
      ],
      "metadata": {
        "id": "2brM4hcr1JMI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTUivFrc9MPb"
      },
      "source": [
        "### Финальное предсказание и отчёт\n",
        "\n",
        "Проведите предсказание еще раз и сравните качество с исходным. Запишите свои наблюдения - как изменялось качество обучения модели при использовании разных модификаций данных."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Запуск со средним значением из 2 задачи"
      ],
      "metadata": {
        "id": "khzQ4zUw6u4C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "5Mw0lpUh9MPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f7c4887-df09-4bdc-bdf3-2471f0a602f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.27060316, 0.2757387 , 0.12815065, 0.22059342])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "scores = pd.read_csv('scores.csv')\n",
        "X = data.values\n",
        "y = scores.values\n",
        "model = LinearRegression()\n",
        "res = cross_validate(model, data.values, scores.values, cv = 4)\n",
        "res['test_score']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запуск с медианным значением из второй задачи"
      ],
      "metadata": {
        "id": "TtqCPm1l6119"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)\n",
        "scores = pd.read_csv('scores.csv')\n",
        "X = data.values\n",
        "y = scores.values\n",
        "model = LinearRegression()\n",
        "res = cross_validate(model, data.values, scores.values, cv = 4)\n",
        "res['test_score']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDqTeAyU60ej",
        "outputId": "c4d055c8-fbf1-4be8-b0be-8d4542021789"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          age  Medu  Fedu  traveltime  studytime  famrel  freetime  goout  \\\n",
            "0    0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "1    0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "2    0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "3    0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "4    0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "..        ...   ...   ...         ...        ...     ...       ...    ...   \n",
            "644  0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "645  0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "646  0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "647  0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "648  0.285714   0.5   0.5         0.0   0.333333    0.75       0.5    0.5   \n",
            "\n",
            "     Dalc  Walc  health  sex_M  address_U  famsize_LE3  Pstatus_T  nursery  \\\n",
            "0     0.0  0.25    0.75      0          1            0          1        1   \n",
            "1     0.0  0.25    0.75      0          1            0          1        1   \n",
            "2     0.0  0.25    0.75      0          1            0          1        1   \n",
            "3     0.0  0.25    0.75      0          1            0          1        1   \n",
            "4     0.0  0.25    0.75      0          1            0          1        1   \n",
            "..    ...   ...     ...    ...        ...          ...        ...      ...   \n",
            "644   0.0  0.25    0.75      0          1            0          1        1   \n",
            "645   0.0  0.25    0.75      0          1            0          1        1   \n",
            "646   0.0  0.25    0.75      0          1            0          1        1   \n",
            "647   0.0  0.25    0.75      0          1            0          1        1   \n",
            "648   0.0  0.25    0.75      0          1            0          1        1   \n",
            "\n",
            "    plans_university past_failures   attend  support  \n",
            "0                1.0           0.0  0.81250        0  \n",
            "1                1.0           0.0  0.93750        0  \n",
            "2                1.0           0.0  1.00000        0  \n",
            "3                1.0           0.0  0.68750        0  \n",
            "4                1.0           0.0  1.00000        0  \n",
            "..               ...           ...      ...      ...  \n",
            "644              1.0           0.0  0.93750        0  \n",
            "645              1.0           0.0  0.93750        0  \n",
            "646              1.0           0.0  0.34375        0  \n",
            "647              1.0           0.0  0.81250        0  \n",
            "648              1.0           0.0  0.93750        0  \n",
            "\n",
            "[649 rows x 20 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.05207104,  0.00912757, -0.01473885, -0.00685901])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Отчет\n",
        "Качество обучения при модифицированных данных поменялось не сильно(видимо из-за небольшого объема неверных данных по сравнению со всеми данными), задание было прикольное, мне понравилось, делал вместе с Артемом Багринцевым. К сожалению не получилось нормально запустить с медианным значением(не смогли найти багу)"
      ],
      "metadata": {
        "id": "s8ItRlI6skpU"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}